---
title: "Visualizing the Bayesian Workflow"
author: "Michal Malyska"
date: "February 26 2020"
output: 
  pdf_document:
    number_sections: true
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


# Introduction

This lab will be looking at trying to replicate some of the visualizations in the lecture notes, involving prior and posterior predictive checks, and LOO model comparisons. 

The dataset is a 0.1% of all births in the US in 2017. I've pulled out a few different variables, but as in the lecture, we'll just focus on birth weight and gestational age. 

# The data

Read it in, along with all our packages. 

```{r, message=FALSE, warning=FALSE}
# the ol' faves
library(tidyverse)
library(here)
# for bayes stuff
library(rstan)
library(bayesplot) # PPCs
library(loo) # does what it says on the packet
library(tidybayes) # may or may not be needed, but I like it

ds <- read_rds(here("data","births_2017_sample.RDS"))
head(ds)
```

Brief overview of variables:

- `mager` mum's age
- `mracehisp` mum's race/ethnicity see here for codes: https://data.nber.org/natality/2017/natl2017.pdf page 15
- `meduc` mum's education see here for codes: https://data.nber.org/natality/2017/natl2017.pdf page 16
- `bmi` mum's bmi 
- `sex` baby's sex
- `combgest` gestational age in weeks
- `dbwt` birth weight in kg
- `ilive` alive at time of report y/n/ unsure

I'm going to rename some variables, remove any observations with missing gestational age or birth weight, restrict just to babies that were alive, and make a preterm variable. 

```{r}
ds <- ds %>%
  rename(birthweight = dbwt, gest = combgest) %>%
  mutate(preterm = ifelse(gest < 32, "Y", "N")) %>%
  filter(ilive == "Y", gest < 99, birthweight < 9.999)
```


## Question 1

Should sound familiar by now: use plots or tables to show three interesting observations about the data. Remember:

```{r Gestational Age Plots}

ds %>%
  ggplot() +
  aes(x = gest, y = birthweight, color = preterm, group = preterm) +
  geom_point() +
  theme_bw() +
  geom_smooth(method = "lm") +
  labs(title = "Weight vs Gestational Age")

```
First I reproduced the gestation vs birthweight plot from the slides - It shows 
that there seems to be a difference in slopes for preterm vs full term babies 
for birthweight as a function of gestation. However since the cutoff for pre-term is 
not data dependent but rather given it seems a bit arbitrary and moving the cutoff
a bit to the right (>32) would result in slopes getting closer. Plus there is a
big uncertainty in the line since there are significantly fewer datapoints for 
preterm babies.

```{r Mother BMI vs Baby birthweight}

ds %>%
  ggplot() +
  aes(x = bmi, y = birthweight, color = preterm) +
  geom_point(alpha = 0.3) +
  theme_minimal() +
  labs(title = "Mother's BMI vs baby birthweight")

```

I wanted to see whether mother's BMI could be indicative of anything regarding 
our response - birthweight, however what I learned is that the data is clearly
not reliable - people with BMI of 100 don't exist. That's like someone who is 
100 kg and only 1m tall or someone who is 400kg and 2m tall. That would mean
a woman that's around average height (1.65m) would weight ~270kg when giving
birth. Those probably should be recoded as NA's.

```{r}
ds %>%
  mutate(race = as_factor(case_when(
    mracehisp == 1 ~ "NHW",
    mracehisp == 2 ~ "NHB",
    mracehisp == 3 ~ "NHAIAN",
    mracehisp == 4 ~ "NHA",
    mracehisp == 5 ~ "NHOPI",
    mracehisp == 6 ~ "Hisp >1 race",
    mracehisp == 7 ~ "Hisp",
    mracehisp == 8 ~ "Unknown"
  ))) %>%
  group_by(race, sex) %>%
  summarize(
    n = n(),
    mean_gest = mean(gest),
    med_gest = median(gest),
    var_gest = var(gest),
    mean_bw = mean(birthweight),
    med_bw = median(birthweight),
    var_bw = var(birthweight),
    num_preterm = sum(preterm == "Y"),
    prop_preterm = mean(preterm == "Y")
  ) %>%
  arrange(desc(n))
```

Since we are going to model data for babies and we have race of mothers and 
sex of babies available it is good to make a check whether we will be doing a 
disfavour to some group by not modelling them separately / not adding a race
and sex as a factor to account for the differences. I outputted a numerical
summary to look at gestation time and birthweight plus numbers of observations
in each group to see if there are any differences that are clear. There does not
seem to be too much variation in things like proportion of babies born pre-term
but there are some things I would try to look more in depth at like why is the
variance of gestation times so much higher for NHB than others ( I am not comparing to the 
ones with very little data)

- Explain what your graph/ tables show
- Choose a graph type that's appropriate to the data type
- If you use `geom_smooth`, please also plot the underlying data

Feel free to replicate one of the scatter plots in the lectures as one of the interesting observations, as those form the basis of our models. 

# The model

As in lecture, we will look at two candidate models 

Model 1 has log birth weight as a function of log gestational age

$$
\log(y_i) \sim N(\beta_1 + \beta_2\log(x_i), \sigma^2)
$$

Model 2 has an interaction term between gestation and prematurity

$$
\log(y_i) \sim N(\beta_1 + \beta_2\log(x_i) + \beta_2 z_i + \beta_4\log(x_i) z_i, \sigma^2)
$$

- $y_i$ is weight in kg
- $x_i$ is gestational age in weeks, CENTERED AND STANDARDIZED
- $z_i$ is preterm (0 or 1, if gestational age is less than 32 weeks)


# Prior predictive checks

Let's put some weakly informative priors on all parameters i.e. for the $\beta$s

$$
\beta \sim N(0, 1)
$$

and for $\sigma$

$$
\sigma \sim N^+(0,1)
$$
where the plus means positive values only i.e. Half Normal. 

Let's check to see what the resulting distribution of birth weights look like given Model 1 and the priors specified above, assuming we had no data on birth weight (but observations of gestational age).

## Question 2

For Model 1, simulate values of $\beta$s and $\sigma$ based on the priors above. Use these values to simulate (log) birth weights from the likelihood specified in Model 1, based on the set of observed gestational weights. Plot the resulting distribution of simulated (log) birth weights. Do 1000 simulations. Here's some skeleton code. Remember to set `eval = TRUE` before you submit. **Also the gestational weights should be centered and standardized**. 

```{r}
set.seed(182)
nsims <- 1000
sigma <- abs(rnorm(nsims))
beta0 <- rnorm(nsims)
beta1 <- rnorm(nsims)

# a tibble to store simulations
# we will calculate likelihood based on observed set of (log, centered, standarized) gestational lengths
lgc <- ds %>% mutate(log_gests_centered = scale(log(gest))) %>% pull(log_gests_centered)
dsims <- tibble(log_gest_c = lgc) 

for (i in 1:nsims) {
  this_mu <- beta0[i] + beta1[i] * dsims$log_gest_c
  dsims[paste0(i)] <- rnorm(3842, mean = this_mu, sd = sigma[i])
}

# plot histogram
data_for_plot <- dsims %>% select(-log_gest_c) %>% pivot_longer(cols = everything()) 
data_for_plot %>%
  ggplot(aes(x = value)) + 
  geom_histogram(bins = 100) +
  theme_minimal() +
  scale_x_continuous(name = "birthweight")

```

# Run the model

Now we're going to run Model 1 in Stan. The stan code is in the `code/models` folder. 

First, get our data into right form for input into stan. 

```{r}
ds$log_weight <- log(ds$birthweight)
ds$log_gest_c <- (log(ds$gest) - mean(log(ds$gest)))/sd(log(ds$gest))

# put into a list
stan_data <- list(N = nrow(ds),
                  log_weight = ds$log_weight,
                  log_gest = ds$log_gest_c)
```

Now fit the model

```{r}
mod1 <- stan(data = stan_data, 
             file = here("code/models/", "simple_weight.stan"),
             iter = 500,
             seed = 243)
```

```{r}
summary(mod1)$summary[c("beta[1]", "beta[2]", "sigma"),]
```

## Question 3

Write a stan model to run Model 2, and run it. There are three options (probably more) to alter the existing stan code

1. add in prematurity and interaction betas to the equation, pass the interaction covariate in as data
2. add in prematurity and interaction betas to the equation, calculate the interaction in a `transformed data` block in the stan model (put it after the data block). this would look something like

```{stan output.var="ex", eval = F}
transformed data {
  vector[N] inter;           // interaction
  inter     = log_gest .* preterm;
}
```

3. change the whole format of the model to be similar to the kids examples from last time where the design matrix was being inputted, rather than individual variables. 

To run the model, your code should look something like this (set `eval = T` to run)

```{r, eval = T}
preterm <- ifelse(ds$preterm == "Y", 1, 0)

# add preterm to list
# note if you are also inputting interaction you will need to add this
stan_data[["preterm"]] <- preterm

mod2 <- stan(data = stan_data, 
             file = here("code/models/", "simple_weight_interaction.stan"),
             iter = 250,
             seed = 243)

summary(mod2)$summary[c(paste0("beta[", 1:4, "]"), "sigma"),]
```

## Question 4

For reference I have uploaded some model 2 results. Check your results are similar. 

```{r}
load(here("output", "mod2.Rda"))
summary(mod2)$summary[c(paste0("beta[", 1:4, "]"), "sigma"),]

```

# PPCs

Now we've run two candidate models let's do some posterior predictive checks. The `bayesplot` package has a lot of inbuilt graphing functions to do this. For example, let's plot the distribution of our data (y) against 100 different datasets drawn from the posterior predictive distribution:

```{r}
set.seed(1856)
y <- ds$log_weight
yrep1 <- extract(mod1)[["log_weight_rep"]]
yrep2 <- extract(mod2)[["log_weight_rep"]] # will need mod2 for later
samp100 <- sample(nrow(yrep1), 100)
ppc_dens_overlay(y, yrep1[samp100, ])  + ggtitle("distribution of observed versus predicted birthweights")
```

## Question 5

Make a similar plot to the one above but for model 2, and **not** using the bayes plot in built function (i.e. do it yourself just with `geom_density`)

```{r}
samp100_2 <- sample(nrow(yrep2), 100)
y2 <- as_tibble(t(yrep2[samp100_2, ]))

# data easier to plot
colnames(y2) <- 1:100

dr <- as_tibble(y2)
dr <- dr %>% bind_cols(i = 1:3842, log_weight_obs = log(ds$birthweight))

dr <- dr %>% 
  pivot_longer(`1`:`100`, names_to = "sim", values_to = "log_weight_rep")

# plot densities for 100 samples

set.seed(176)

dr %>% 
  ggplot(aes(log_weight_rep, group = sim)) + 
  geom_density(alpha = 0.2, aes(color = "y_rep")) + 
  geom_density(data = ds %>% mutate(sim = 1), 
               aes(x = log(birthweight), col = "y")) + 
  scale_color_manual(name = "", 
                     values = c("y" = "darkblue", 
                                "y_rep" = "lightblue")) + 
  ggtitle("Distribution of observed vs predicted birthweights") + 
  theme_bw(base_size = 16)

```

This seemed super narrow at first but it is just because of the x axis scale.

```{r}
dr %>% 
  ggplot(aes(log_weight_rep, group = sim)) + 
  geom_density(alpha = 0.2, aes(color = "y_rep")) + 
  geom_density(data = ds %>% mutate(sim = 1), 
               aes(x = log(birthweight), col = "y")) + 
  scale_color_manual(name = "", 
                     values = c("y" = "darkblue", 
                                "y_rep" = "lightblue")) + 
  ggtitle("Distribution of observed vs predicted birthweights") + 
  theme_bw(base_size = 16) +
  scale_x_continuous(limits = c(-1, 2))
```

## Test statistics

We can also look at some summary statistics in the PPD versus the data, again either using `bayesplot` -- the function of interest is `ppc_stat` or `ppc_stat_grouped` -- or just doing it ourselves using ggplot. 

E.g. medians by prematurity for Model 1

```{r}
ppc_stat_grouped(ds$log_weight, yrep1, group = ds$preterm, stat = 'median')
```

## Question 6

Use a test statistic of the proportion of births under 2.5kg. Calculate the test statistic for the data, and the posterior predictive samples for both models, and plot the comparison (one plot per model). 

```{r}
test_stat_real <- mean(ds$birthweight < 2.5)
test_stat_rep <- dr %>% group_by(sim) %>%
  summarize(test_stat = mean(exp(log_weight_rep) < 2.5))

test_stat_rep %>%
  ggplot(aes(x = test_stat)) +
  geom_histogram(bins = 20, fill = "lightblue") +
  geom_vline(xintercept = test_stat_real, color = "darkblue") +
  theme_minimal() +
  labs(caption = "simulated test statistics in light blue \n real test statistic in dark blue",
       title = "Test Statistics for PPC for proportion of bw < 2.5kg")

```


# LOO

Finally let's calculate the LOO elpd for each model and compare. The first step of this is to get the point-wise log likelihood estimates from each model:

```{r}
loglik1 <- extract(mod1)[["log_lik"]]
loglik2 <- extract(mod2)[["log_lik"]]
```


And then we can use these in the `loo` function to get estimates for the elpd. Note the `save_psis = TRUE` argument saves the calculation for each simulated draw, which is needed for the LOO-PIT calculation below. 

```{r}
loo1 <- loo(loglik1, save_psis = TRUE)
loo2 <- loo(loglik2, save_psis = TRUE)
```

Look at the output:


```{r}
loo1
loo2
```

Comparing the two models tells us Model 2 is better:

```{r}
loo_compare(loo1, loo2)
```

We can also compare the LOO-PIT of each of the models to standard uniforms. The both do pretty well. 

```{r}
ppc_loo_pit_overlay(yrep = yrep1, y = y, lw = weights(loo1$psis_object))
ppc_loo_pit_overlay(yrep = yrep2, y = y, lw = weights(loo2$psis_object))
```

